{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3e83364e-f050-470b-b58f-643902e996b5",
   "metadata": {},
   "source": [
    "### CT1 - Assignment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b3ffd5d-2a98-418d-91af-3003265a2b6e",
   "metadata": {},
   "source": [
    "### A. Initial Setup and Ingestion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "45a4621f-f9ba-4d57-8651-e9f0a8dc54b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.97      0.95       734\n",
      "           1       0.68      0.47      0.55        90\n",
      "\n",
      "    accuracy                           0.92       824\n",
      "   macro avg       0.81      0.72      0.75       824\n",
      "weighted avg       0.91      0.92      0.91       824\n",
      "\n",
      "ROC-AUC: 0.9463\n",
      "Confusion matrix:\n",
      " [[714  20]\n",
      " [ 48  42]]\n",
      "ROC-AUC: 0.9462534059945504\n",
      "Saved full pipeline to models/gb_bank_pipeline.joblib\n"
     ]
    }
   ],
   "source": [
    "# bank_mlops_pipeline.py\n",
    "\n",
    "import os\n",
    "import joblib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.metrics import (\n",
    "    classification_report,\n",
    "    roc_auc_score,\n",
    "    confusion_matrix,\n",
    ")\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# ---------- Paths ----------\n",
    "DATA_PATH = \"bank-additional.csv\"\n",
    "MODEL_DIR = \"models\"\n",
    "MODEL_PATH = os.path.join(MODEL_DIR, \"gb_bank_pipeline.joblib\")\n",
    "\n",
    "\n",
    "# ---------- Data ingestion ----------\n",
    "def load_data(path: str) -> pd.DataFrame:\n",
    "    df = pd.read_csv(path, sep=\",\")\n",
    "    return df\n",
    "\n",
    "\n",
    "# ---------- Preâ€‘processing ----------\n",
    "def basic_cleaning(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    df.columns = df.columns.str.strip()\n",
    "    df = df.drop_duplicates()\n",
    "    df = df.replace(\"unknown\", np.nan)\n",
    "    return df\n",
    "\n",
    "\n",
    "def split_features_target(df: pd.DataFrame):\n",
    "    X = df.drop(columns=[\"y\"])\n",
    "    y = df[\"y\"].map({\"no\": 0, \"yes\": 1})\n",
    "    return X, y\n",
    "\n",
    "\n",
    "# ---------- Feature engineering / preprocessor ----------\n",
    "def build_preprocessor(X: pd.DataFrame) -> ColumnTransformer:\n",
    "    numeric_features = [\n",
    "        \"age\",\n",
    "        \"duration\",\n",
    "        \"campaign\",\n",
    "        \"pdays\",\n",
    "        \"previous\",\n",
    "        \"emp.var.rate\",\n",
    "        \"cons.price.idx\",\n",
    "        \"cons.conf.idx\",\n",
    "        \"euribor3m\",\n",
    "        \"nr.employed\",\n",
    "    ]\n",
    "\n",
    "    # Column name can be day_of_week or dayofweek depending on file\n",
    "    day_col = \"day_of_week\" if \"day_of_week\" in X.columns else \"dayofweek\"\n",
    "\n",
    "    categorical_features = [\n",
    "        \"job\",\n",
    "        \"marital\",\n",
    "        \"education\",\n",
    "        \"default\",\n",
    "        \"housing\",\n",
    "        \"loan\",\n",
    "        \"contact\",\n",
    "        \"month\",\n",
    "        day_col,\n",
    "        \"poutcome\",\n",
    "    ]\n",
    "\n",
    "    numeric_features = [c for c in numeric_features if c in X.columns]\n",
    "    categorical_features = [c for c in categorical_features if c in X.columns]\n",
    "\n",
    "    numeric_transformer = StandardScaler()\n",
    "\n",
    "    categorical_transformer = OneHotEncoder(\n",
    "        handle_unknown=\"ignore\",\n",
    "        sparse_output=False  # use sparse=False if on older sklearn\n",
    "    )\n",
    "\n",
    "    preprocessor = ColumnTransformer(\n",
    "        transformers=[\n",
    "            (\"num\", numeric_transformer, numeric_features),\n",
    "            (\"cat\", categorical_transformer, categorical_features),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    return preprocessor\n",
    "\n",
    "\n",
    "# ---------- Model ----------\n",
    "def build_model(preprocessor: ColumnTransformer) -> Pipeline:\n",
    "    gb = GradientBoostingClassifier(\n",
    "        n_estimators=200,\n",
    "        learning_rate=0.05,\n",
    "        max_depth=3,\n",
    "        random_state=42,\n",
    "    )\n",
    "\n",
    "    pipe = Pipeline(\n",
    "        steps=[\n",
    "            (\"preprocess\", preprocessor),\n",
    "            (\"model\", gb),\n",
    "        ]\n",
    "    )\n",
    "    return pipe\n",
    "\n",
    "\n",
    "# ---------- Evaluation helpers ----------\n",
    "def plot_basic_eda(df: pd.DataFrame):\n",
    "    # Target distribution\n",
    "    plt.figure(figsize=(4, 3))\n",
    "    df[\"y\"].value_counts().plot(kind=\"bar\")\n",
    "    plt.title(\"Target distribution (y)\")\n",
    "    plt.xlabel(\"Class\")\n",
    "    plt.ylabel(\"Count\")\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(\"eda_target_distribution.png\")\n",
    "    plt.close()\n",
    "\n",
    "    # Duration vs target\n",
    "    plt.figure(figsize=(4, 3))\n",
    "    sns.boxplot(x=\"y\", y=\"duration\", data=df)\n",
    "    plt.title(\"Call duration vs term deposit\")\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(\"eda_duration_vs_y.png\")\n",
    "    plt.close()\n",
    "\n",
    "\n",
    "def evaluate_model(model: Pipeline, X_test, y_test):\n",
    "    y_pred = model.predict(X_test)\n",
    "    y_proba = model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "    print(\"Classification report:\")\n",
    "    print(classification_report(y_test, y_pred))\n",
    "\n",
    "    auc = roc_auc_score(y_test, y_proba)\n",
    "    print(f\"ROC-AUC: {auc:.4f}\")\n",
    "\n",
    "    # Confusion matrix\n",
    "    cm = confusion_matrix(y_test, y_pred)  # [[TN, FP], [FN, TP]]\n",
    "\n",
    "    plt.figure(figsize=(4, 3))\n",
    "    sns.heatmap(\n",
    "        cm,\n",
    "        annot=True,\n",
    "        fmt=\"d\",\n",
    "        cmap=\"Blues\",\n",
    "        xticklabels=[\"No\", \"Yes\"],\n",
    "        yticklabels=[\"No\", \"Yes\"],\n",
    "    )\n",
    "    plt.xlabel(\"Predicted\")\n",
    "    plt.ylabel(\"Actual\")\n",
    "    plt.title(\"Confusion Matrix - Gradient Boosting\")\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(\"confusion_matrix_gb.png\")\n",
    "    plt.close()\n",
    "\n",
    "    return cm, auc\n",
    "\n",
    "\n",
    "# ---------- Persistence ----------\n",
    "def save_model(model: Pipeline):\n",
    "    os.makedirs(MODEL_DIR, exist_ok=True)\n",
    "    joblib.dump(model, MODEL_PATH)\n",
    "    print(f\"Saved full pipeline to {MODEL_PATH}\")\n",
    "\n",
    "\n",
    "def load_model(path: str = MODEL_PATH) -> Pipeline:\n",
    "    return joblib.load(path)\n",
    "\n",
    "\n",
    "# ---------- Main ----------\n",
    "def main():\n",
    "    # 1. Ingestion\n",
    "    df = load_data(DATA_PATH)\n",
    "\n",
    "    # 2. Cleaning / preprocessing\n",
    "    df = basic_cleaning(df)\n",
    "\n",
    "    # Optional: quick EDA plots\n",
    "    plot_basic_eda(df)\n",
    "\n",
    "    # 3. Features / target\n",
    "    X, y = split_features_target(df)\n",
    "\n",
    "    # 4. Train / test split\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=0.2, stratify=y, random_state=42\n",
    "    )\n",
    "\n",
    "    # 5. Preprocessor + model\n",
    "    preprocessor = build_preprocessor(X_train)\n",
    "    model = build_model(preprocessor)\n",
    "\n",
    "    # 6. Train\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # 7. Evaluate (report, ROC-AUC, confusion matrix image)\n",
    "    cm, auc = evaluate_model(model, X_test, y_test)\n",
    "    print(\"Confusion matrix:\\n\", cm)\n",
    "    print(\"ROC-AUC:\", auc)\n",
    "\n",
    "    # 8. Persist\n",
    "    save_model(model)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27f030f1-ca26-4473-902d-30e81e637732",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
